import pandas as pd
import numpy as np
from sklearn.neighbors import LocalOutlierFactor
from sklearn import metrics
from sklearn.model_selection import StratifiedKFold
from imblearn.metrics import geometric_mean_score
from sklearn.tree import DecisionTreeClassifier
from imblearn.over_sampling import ADASYN, SMOTE
from imblearn.under_sampling import NeighbourhoodCleaningRule, OneSidedSelection
from imblearn.combine import SMOTEENN, SMOTETomek
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import roc_curve, auc
from scipy import interp
from os.path import join
from sklearn import svm

# %% create chess dataset

RANDOM_SEED = 123123  # fix the seed on each iteration
np.random.seed(RANDOM_SEED)

# Parameters
div = 4 #int(sys.argv[1])
N = 1000 #int(sys.argv[2])
per = 0.1 #float(sys.argv[3])

lim = []
for i in range(1, div):
	lim.append(i/float(div))
print(lim)

X=[]
Y=[]
Xo=[]
Yo=[]
#Generation of the Synthetic data
for i in range(0,N):
	x = [0,0]
	x[0] = np.random.uniform(0,1)
	x[1] = np.random.uniform(0,1)

	y=0

	ind = 0
	while ind < len(lim) and x[0] > lim[ind]:
		ind+=1

	y=(ind)%2

	ind = 0
	while ind < len(lim) and x[1] > lim[ind]:
		ind+=1

	if y == 0:
		y = (ind)%2
	else:
		y = (ind-1)%2

	Xo.append(x)
	Yo.append(y)
	if y==0 or (y == 1 and np.random.uniform(0,1) < per):
		X.append(x)
		Y.append(y)


X=np.array(X)
y=np.array(Y)
Xo=np.array(Xo)
yo=np.array(Yo)


# %% HVDM metric

# HVDM metric for numerical attribute
def nor_diff(x, y):
    scale = 4 * np.nanstd(X, axis=0)
    result = np.sum(np.square(abs(x - y) / scale))
    return result

# compute the distance metric
dis_metric = np.zeros((X.shape[0], X.shape[0]))

for i in range(X.shape[0]):
    inx = [i] * X.shape[0]
    for j, p in enumerate(inx):
        dis_metric[p, j] = nor_diff(X[p], X[j])

for i, j in enumerate(range(X.shape[0])):
    dis_metric[i, j] = 1000000


num_neighbor = 5

top = np.argpartition(dis_metric, num_neighbor, axis=1)[:, :num_neighbor]
dis_neighbor = dis_metric[np.arange(dis_metric.shape[0])[:, None], top]  # compute neighbors for every sample


count_neighbor = np.zeros((X.shape[0], num_neighbor+2))  # count the types of neighbors and decide type

for i in range(count_neighbor.shape[0]):
    count_neighbor[i, :num_neighbor] = y[top[i, :]]
    count_neighbor[i, num_neighbor] = abs(5 * y[i] -
                                          np.sum(count_neighbor[i, :num_neighbor]))
    if count_neighbor[i, num_neighbor] == 5:
        count_neighbor[i, num_neighbor+1] = 0.1
    elif count_neighbor[i, num_neighbor] == 4:
        count_neighbor[i, num_neighbor+1] = 0.25
    elif count_neighbor[i, num_neighbor] == 3:
        count_neighbor[i, num_neighbor+1] = 0.4
    elif count_neighbor[i, num_neighbor] == 2:
        count_neighbor[i, num_neighbor+1] = 0.6
    elif count_neighbor[i, num_neighbor] == 1:
        count_neighbor[i, num_neighbor+1] = 0.8
    else:
        count_neighbor[i, num_neighbor+1] = 1


y_1 = np.array([y[x:x+1] for x in range(0, len(y), 1)])
X_all = np.concatenate([X, y_1], axis=1)
X_all = pd.DataFrame(X_all, columns=['input1', 'input2', 'Class'])

X_all['degree'] = count_neighbor[:, num_neighbor+1]


# %% produce LOF score

ir = len(y[y == 1]) / len(y[y == 0])
clf = LocalOutlierFactor(n_neighbors=10, contamination=ir)  # highly rely on the IR in training set
y_pred = clf.fit_predict(X)
X_scores = clf.negative_outlier_factor_
X_scores_1 = np.array([X_scores[x:x + 1] for x in range(0, len(X_scores), 1)])  # change shape (n,) to (n, 1)
X_all['LOF'] = X_scores_1

#  # experiment with LOF score
X_new = X_all.drop(['Class'], axis=1)
X_add = StandardScaler().fit_transform(X_new)
X_add = np.c_[X_add]


# %% baseline Decision Tree

RANDOM_SEED_ALL = list(range(30))


performance = np.zeros(shape=(30, 5))

for random in RANDOM_SEED_ALL:

    k = 5
    cv = StratifiedKFold(n_splits=k)

    tprs = []
    aucs = []
    precision = []
    recall = []
    f1 = []
    gmean = []
    mean_fpr = np.linspace(0, 1, 100)

    for train, test in cv.split(X, y):

        clf = DecisionTreeClassifier(min_samples_leaf=2, random_state=random) #.fit(X[train], y[train])
        #clf = svm.SVC(gamma='scale', probability=True, random_state=random)

        probas_ = clf.fit(X[train], y[train]).predict_proba(X[test])

        # Compute ROC curve and area the curve
        fpr, tpr, thresholds = roc_curve(y[test], probas_[:, 1])
        tprs.append(interp(mean_fpr, fpr, tpr))
        tprs[-1][0] = 0.0
        roc_auc = auc(fpr, tpr)
        aucs.append(roc_auc)

        y_test_pred = clf.predict(X[test])
        pre = metrics.precision_score(y[test], y_test_pred)  # precision
        rec = metrics.recall_score(y[test], y_test_pred)  # recall
        f11 = metrics.f1_score(y[test], y_test_pred)  # f1_score
        gm = geometric_mean_score(y[test], y_test_pred, average='binary')

        precision.append(pre)
        recall.append(rec)
        f1.append(f11)
        gmean.append(gm)

    mean_tpr = np.mean(tprs, axis=0)
    mean_tpr[-1] = 1.0
    mean_auc = auc(mean_fpr, mean_tpr)
    performance[random, :] = [mean_auc, np.mean(precision), np.mean(recall), np.mean(f1), np.mean(gmean)]

performance = pd.DataFrame(performance, columns=['AUC', 'precision', 'recall', 'F-measure', 'Gmean'])
a = join(r'C:\Users\Dell Latitude\surfdrive\Documents\CODE_BACKUP\Pconf\myenv\results\DecisionTree\chess_baseline.csv')
performance.to_csv(a)
    
    
# %% baseline Decision Tree with added attributes

RANDOM_SEED_ALL = list(range(30))


performance = np.zeros(shape=(30, 5))

for random in RANDOM_SEED_ALL:

    k = 5
    cv = StratifiedKFold(n_splits=k)

    tprs = []
    aucs = []
    precision = []
    recall = []
    f1 = []
    gmean = []
    mean_fpr = np.linspace(0, 1, 100)

    for train, test in cv.split(X_add, y):

        clf = DecisionTreeClassifier(min_samples_leaf=2, random_state=random) #.fit(X[train], y[train])
        #clf = svm.SVC(gamma='scale', probability=True, random_state=random)

        probas_ = clf.fit(X_add[train], y[train]).predict_proba(X_add[test])

        # Compute ROC curve and area the curve
        fpr, tpr, thresholds = roc_curve(y[test], probas_[:, 1])
        tprs.append(interp(mean_fpr, fpr, tpr))
        tprs[-1][0] = 0.0
        roc_auc = auc(fpr, tpr)
        aucs.append(roc_auc)

        y_test_pred = clf.predict(X_add[test])
        pre = metrics.precision_score(y[test], y_test_pred)  # precision
        rec = metrics.recall_score(y[test], y_test_pred)  # recall
        f11 = metrics.f1_score(y[test], y_test_pred)  # f1_score
        gm = geometric_mean_score(y[test], y_test_pred, average='binary')

        precision.append(pre)
        recall.append(rec)
        f1.append(f11)
        gmean.append(gm)

    mean_tpr = np.mean(tprs, axis=0)
    mean_tpr[-1] = 1.0
    mean_auc = auc(mean_fpr, mean_tpr)
    performance[random, :] = [mean_auc, np.mean(precision), np.mean(recall), np.mean(f1), np.mean(gmean)]
    
performance = pd.DataFrame(performance, columns=['AUC', 'precision', 'recall', 'F-measure', 'Gmean'])
a = join(r'C:\Users\Dell Latitude\surfdrive\Documents\CODE_BACKUP\Pconf\myenv\results\DecisionTree\chess_add_baseline.csv')
performance.to_csv(a)


# %% 30 times * different sample without 'degree' & 'LOF' Decision Tree

RANDOM_SEED_ALL = list(range(30))

names = ['ADASYN', 'SMOTE', 'NCL', 'OSS', 'SMOTEENN', 'SMOTETomek']
methods = [ADASYN(), SMOTE(),
           NeighbourhoodCleaningRule(n_neighbors=20),
           OneSidedSelection(n_neighbors=1, n_seeds_S=100),
           SMOTEENN(), SMOTETomek()]

for name, sampler in zip(names, methods):

    #name = names[1]
    #sampler = methods[1]
    #random = 1

    performance = np.zeros(shape=(30, 5))

    for random in RANDOM_SEED_ALL:

        k = 5
        cv = StratifiedKFold(n_splits=k)

        tprs = []
        aucs = []
        precision = []
        recall = []
        f1 = []
        gmean = []
        mean_fpr = np.linspace(0, 1, 100)

        for train, test in cv.split(X, y):
            Xr, yr = sampler.fit_sample(X[train], y[train])
            clf = DecisionTreeClassifier(min_samples_leaf=2, random_state=random).fit(Xr, yr)
            #clf = svm.SVC(gamma='scale', probability=True, random_state=random)

            probas_ = clf.fit(Xr, yr).predict_proba(X[test])

            # Compute ROC curve and area the curve
            fpr, tpr, thresholds = roc_curve(y[test], probas_[:, 1])
            tprs.append(interp(mean_fpr, fpr, tpr))
            tprs[-1][0] = 0.0
            roc_auc = auc(fpr, tpr)
            aucs.append(roc_auc)

            y_test_pred = clf.predict(X[test])
            pre = metrics.precision_score(y[test], y_test_pred)  # precision
            rec = metrics.recall_score(y[test], y_test_pred)  # recall
            f11 = metrics.f1_score(y[test], y_test_pred)  # f1_score
            gm = geometric_mean_score(y[test], y_test_pred, average='binary')

            precision.append(pre)
            recall.append(rec)
            f1.append(f11)
            gmean.append(gm)

        mean_tpr = np.mean(tprs, axis=0)
        mean_tpr[-1] = 1.0
        mean_auc = auc(mean_fpr, mean_tpr)
        performance[random, :] = [mean_auc, np.mean(precision), np.mean(recall), np.mean(f1), np.mean(gmean)]

    performance = pd.DataFrame(performance, columns=['AUC', 'precision', 'recall', 'F-measure', 'Gmean'])
    a = join(r'C:\Users\Dell Latitude\surfdrive\Documents\CODE_BACKUP\Pconf\myenv\results\DecisionTree', str(name)+'_pageblock_original.csv')
    performance.to_csv(a)


# %% 30 times * different sample without 'degree' & 'LOF' Decision Tree

RANDOM_SEED_ALL = list(range(30))

names = ['ADASYN', 'SMOTE', 'NCL', 'OSS', 'SMOTEENN', 'SMOTETomek']
methods = [ADASYN(), SMOTE(),
           NeighbourhoodCleaningRule(n_neighbors=20),
           OneSidedSelection(n_neighbors=1, n_seeds_S=100),
           SMOTEENN(), SMOTETomek()]

for name, sampler in zip(names, methods):
    #name = names[5]
    #sampler = methods[5]

    performance = np.zeros(shape=(30, 5))

    for random in RANDOM_SEED_ALL:

        k = 5
        cv = StratifiedKFold(n_splits=k)

        tprs = []
        aucs = []
        precision = []
        recall = []
        f1 = []
        gmean = []
        mean_fpr = np.linspace(0, 1, 100)

        for train, test in cv.split(X_add, y):
            Xr, yr = sampler.fit_sample(X_add[train], y[train])
            clf = DecisionTreeClassifier(min_samples_leaf=2, random_state=random).fit(Xr, yr)
            #clf = svm.SVC(gamma='scale', probability=True, random_state=random)

            probas_ = clf.fit(Xr, yr).predict_proba(X_add[test])

            # Compute ROC curve and area the curve
            fpr, tpr, thresholds = roc_curve(y[test], probas_[:, 1])
            tprs.append(interp(mean_fpr, fpr, tpr))
            tprs[-1][0] = 0.0
            roc_auc = auc(fpr, tpr)
            aucs.append(roc_auc)

            y_test_pred = clf.predict(X_add[test])
            pre = metrics.precision_score(y[test], y_test_pred)  # precision
            rec = metrics.recall_score(y[test], y_test_pred)  # recall
            f11 = metrics.f1_score(y[test], y_test_pred)  # f1_score
            gm = geometric_mean_score(y[test], y_test_pred, average='binary')

            precision.append(pre)
            recall.append(rec)
            f1.append(f11)
            gmean.append(gm)

        mean_tpr = np.mean(tprs, axis=0)
        mean_tpr[-1] = 1.0
        mean_auc = auc(mean_fpr, mean_tpr)
        performance[random, :] = [mean_auc, np.mean(precision), np.mean(recall), np.mean(f1), np.mean(gmean)]

    performance = pd.DataFrame(performance, columns=['AUC', 'precision', 'recall', 'F-measure', 'Gmean'])
    a = join(r'C:\Users\Dell Latitude\surfdrive\Documents\CODE_BACKUP\Pconf\myenv\results\DecisionTree', str(name)+'_pageblock_add.csv')
    performance.to_csv(a)
